% !TeX root = ../main.tex

\section*{Hidden Markov Models HMM}
TODO:

\subsection*{Remakrs on HMM}

3 algorithmes
\begin{enumerate}
    \item  How to train the HMM (determain the parameters $\lambda (A, B, \pi)$)
    \item  Determine the propbaility of a symbole being produced
    \item  Recover the most likly state sequence
\end{enumerate}

\begin{itemize}
    \item the directed edge in a HMM graph can be understood as a statistical dependency $p(S_2|S_1)$ (more section 8 in bishops book on pattern recognition)
    \item generative approch
    \item For many tasks including speach processing, we often only allow state transitions $a_{ij}$ with $i \le j$ (now backward links). So called "left-right-HMMs".
\end{itemize}
